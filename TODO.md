[x] Learnable PE 
[x] post-fusion vs pre-fusion: Change orders of attent layers in decoder: cross-attn -> attn
[x] Concat tgt and src for self-attention
[x] Pre dec PE
[x] Support EMA
[] tune dropout (e.g. 0.1), weight decay (e.g. 0.01), clip_norm (e.g. 1.)